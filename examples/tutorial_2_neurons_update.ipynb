{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled17.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNnKwLFCjWjyi3/9mYMYo5v",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jeshraghian/snntorch/blob/tutorials/examples/tutorial_2_neurons_update.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HzIQBw28NL8h"
      },
      "source": [
        "<img src='https://github.com/jeshraghian/snntorch/blob/master/docs/_static/img/snntorch_alpha_w.png?raw=true' width=\"400\">\r\n",
        "\r\n",
        "# snnTorch - Neuronal Dynamics with ``snntorch``\r\n",
        "## Tutorial 2\r\n",
        "### By Jason K. Eshraghian (www.jasoneshraghian.com)\r\n",
        "\r\n",
        "<a href=\"https://colab.research.google.com/github/jeshraghian/snntorch/blob/tutorials/examples/tutorial_2_neurons.ipynb\">\r\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\r\n",
        "</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ep_Qv7kzNOz6"
      },
      "source": [
        "# Introduction\r\n",
        "In this tutorial, you will:\r\n",
        "* Learn the basics of a leaky integrate-and-fire (LIF)\r\n",
        "* Use snnTorch to implement variations of the LIF model: \r\n",
        "  * Lapicque's LIF neuron model\r\n",
        "  * Stein's neuron model\r\n",
        "  * 0$^{th}$ Order Spike Response Model\r\n",
        "<!-- * Plot the output behavior of the neurons -->\r\n",
        "<!-- * Interpret the computational graph of a spiking neuron -->\r\n",
        "<!-- * Automatically initialize the hidden states of the neurons [keep in tute, but delete explanation]? -->\r\n",
        "* Implement a feedforward spiking neural network\r\n",
        "\r\n",
        ">Part of this tutorial was inspired by the book [*Neuronal Dynamics:\r\n",
        "From single neurons to networks and models of cognition*](https://neuronaldynamics.epfl.ch/index.html) by\r\n",
        "Wulfram Gerstner, Werner M. Kistler, Richard Naud and Liam Paninski.\r\n",
        "\r\n",
        "If running in Google Colab:\r\n",
        "* You may connect to GPU by checking `Runtime` > `Change runtime type` > `Hardware accelerator: GPU`\r\n",
        "* Next, install the latest PyPi distribution of snnTorch by clicking into the following cell and pressing `Shift+Enter`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SPQITvDuNNJg",
        "outputId": "d8c161bc-b5b7-417c-8ef2-a0dd7f6d8704"
      },
      "source": [
        "!pip install snntorch"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting snntorch\n",
            "  Downloading https://files.pythonhosted.org/packages/96/62/af42377ae9c7266bc1bdf63b3b58b9663a60a8e3510fb96d22b76e7ffb80/snntorch-0.2.1-py2.py3-none-any.whl\n",
            "Collecting celluloid\n",
            "  Downloading https://files.pythonhosted.org/packages/60/a7/7fbe80721c6f1b7370c4e50c77abe31b4d5cfeb58873d4d32f48ae5a0bae/celluloid-0.2.0-py3-none-any.whl\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from snntorch) (1.1.5)\n",
            "Requirement already satisfied: torch>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from snntorch) (1.8.0+cu101)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from snntorch) (1.19.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from snntorch) (3.2.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->snntorch) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->snntorch) (2.8.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.2.0->snntorch) (3.7.4.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->snntorch) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->snntorch) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->snntorch) (1.3.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->snntorch) (1.15.0)\n",
            "Installing collected packages: celluloid, snntorch\n",
            "Successfully installed celluloid-0.2.0 snntorch-0.2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xmTt5dvyXNNy"
      },
      "source": [
        "# 1. The Spectrum of Neuron Models\r\n",
        "A large variety of neuron models are out there, ranging from biophysically accurate models (i.e., the Hodgkin-Huxley models) to the extremely simple artificial neuron that pervades all facets of modern deep learning.\r\n",
        "\r\n",
        "**Hodgkin-Huxley Neuron Models**$-$While biophysical models can reproduce electrophysiological results with a high degree of accuracy, their complexity makes them difficult to use. We expect this to change as more rigorous theories of how neurons contribute to higher-order behaviors in the brain are uncovered.\r\n",
        "\r\n",
        "**Artificial Neuron Model**$-$On the other end of the spectrum is the artificial neuron. The inputs are multiplied by their corresponding weights and passed through an activation function. This simplification has enabled deep learning researchers to perform incredible feats in computer vision, natural language processing, and many other machine learning-domain tasks.\r\n",
        "\r\n",
        "**Leaky Integrate-and-Fire Neuron Models**$-$Somewhere in the middle of the divide lies the leaky integrate-and-fire (LIF) neuron model. It takes the sum of weighted inputs, much like the artificial neuron. But rather than passing it directly to an activation function, it will integrate the input over time with a leakage, much like an RC circuit. If the integrated value exceeds a threshold, then the LIF neuron will emit a voltage spike. The LIF neuron abstracts away the shape and profile of the output spike; it is simply treated as a discrete event. As a result, information is not stored within the spike, but rather the timing (or frequency) of spikes. Simple spiking neuron models have produced much insight into the neural code, memory, network dynamics, and more recently, deep learning. The LIF neuron sits in the sweet spot between biological plausibility and practicality. \r\n",
        "\r\n",
        "<center>\r\n",
        "<img src='https://github.com/jeshraghian/snntorch/blob/master/docs/_static/img/examples/tutorial2/2_1_neuronmodels.png?raw=true' width=\"1000\">\r\n",
        "</center>\r\n",
        "\r\n",
        "<!-- Researchers might spend their entire lives dedicated to developing neuron models. Some of these models are straightforward extensions of the HH and LIF models, while other models find completely different applications, such as in neuropharmocology. -->\r\n",
        "\r\n",
        "The different versions of the LIF model each have their own dynamics and use-cases. snnTorch currently supports three types of LIF neurons:\r\n",
        "* Lapicque's RC model: ``snntorch.Lapicque``\r\n",
        "* Stein's neuron model: ``snntorch.Stein``\r\n",
        "* 0$^{th}$ Order Spike Response Model: ``snntorch.SRM0``\r\n",
        "\r\n",
        "Before learning how to use them, let's understand how to construct a simple LIF neuron model.\r\n",
        "\r\n",
        "<!-- In general, the most obvious difference is that the SRM0 model incorporates a delay between the input and output. When an input spike arrives at an SRM0 neuron, the membrane potential will increase over a finite time. If an output spike were to be triggered, it would experience a delay with respect to the input. On the other hand, Stein's model allows for an instantaneous rise of membrane potential. We'll dig into where these might be useful shortly. -->\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nea8oBorr_KZ"
      },
      "source": [
        "# 1. The Leaky Integrate-and-Fire Neuron Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YKsrN5feQ2Dz"
      },
      "source": [
        "## 1.1 Spiking Neurons: Intuition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YGStnfjzsGKb"
      },
      "source": [
        "A neuron might be connected to 1,000 $-$ 10,000 other neurons. If one neuron spikes, all of these downhill neurons will feel it. But what determines whether a neuron spikes in the first place? The past century of experiments demonstrate that if a neuron experiences *sufficient* stimulus at its input, then we might expect it to become excited and fire its own spike. \r\n",
        "\r\n",
        "Where does this stimulus come from? It could be from\r\n",
        "* the sensory periphery, \r\n",
        "* an invasive electrode artificially stimulating the neuron, or in most cases,\r\n",
        "* from other pre-synaptic neurons. \r\n",
        "\r\n",
        "<center>\r\n",
        "<img src='https://github.com/jeshraghian/snntorch/blob/master/docs/_static/img/examples/tutorial2/2_2_intuition.png?raw=true' width=\"800\">\r\n",
        "</center>\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TaVTRojJ2Dl_"
      },
      "source": [
        "Given that these spikes are very short bursts of electrical activity, it is quite unlikely for all input spikes to arrive at the neuron body in precise unison. This indicates the presence of temporal dynamics that 'sustain' the input spikes, kind of like a delay.\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l44jI7A2ReB_"
      },
      "source": [
        "## 1.2 The Passive Membrane"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Od5tfXv6_wcq"
      },
      "source": [
        "Like all cells, a neuron is surrounded by a thin membrane. This membrane is a lipid bilayer that insulates the conductive saline solution within the neuron from the extracellular medium. Electrically, the two conductors separated by an insulator is a capacitor. \r\n",
        "\r\n",
        "Another function of this membrane is to control what goes in and out of this cell (e.g., ions such as Na$^+$). The membrane is usually impermeable to ions which blocks them from entering and exiting the neuron body. But there are specific channels in the membrane that are triggered to open by injecting current into the neuron. This charge movement is electrically modelled by a resistor.\r\n",
        "\r\n",
        "<center>\r\n",
        "<img src='https://github.com/jeshraghian/snntorch/blob/master/docs/_static/img/examples/tutorial2/2_3_passivemembrane.png?raw=true' width=\"800\">\r\n",
        "</center>\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wT_S4b4HL2ir"
      },
      "source": [
        "Now say some arbitrary time-varying current $I_{\\rm in}(t)$ is injected into the neuron, be it via electrical stimulation or from other neurons. The total current in the circuit is conserved, so:\r\n",
        "\r\n",
        "$$I_{\\rm in}(t) = I_{R} + I_{C}$$\r\n",
        "\r\n",
        "From Ohm's Law, the membrane potential measured between the inside and outside of the neuron $U_{\\rm mem}$ is proportional to the current through the resistor:\r\n",
        "\r\n",
        "$$I_{R} = \\frac{U_{\\rm mem}}{R}$$\r\n",
        "\r\n",
        "The capacitance is a proportionality constant between the charge stored on the capacitor $Q$ and $U_{\\rm mem}$:\r\n",
        "\r\n",
        "\r\n",
        "$$Q = CU_{\\rm mem}$$\r\n",
        "\r\n",
        "The rate of change of charge gives the capacitive current:\r\n",
        "\r\n",
        "$$\\frac{dQ}{dt}=I_C = C\\frac{dU_{\\rm mem}}{dt}$$\r\n",
        "\r\n",
        "Therefore:\r\n",
        "\r\n",
        "$$I_{\\rm in}(t) = \\frac{U_{\\rm mem}}{R} + C\\frac{dU_{\\rm mem}}{dt}$$\r\n",
        "$$\\implies RC \\frac{dU_{\\rm mem}}{dt} = -U_{\\rm mem} + RI_{\\rm in}(t)$$\r\n",
        "\r\n",
        "The right hand side of the equation is **\\[Voltage]**. On the left hand side of the equation, the term $\\frac{dU_{\\rm mem}}{dt}$ is of units **\\[Voltage/Time]**. To equate it to a voltage, $RC$ must be of unit **\\[Time]**. We refer to $\\tau = RC$ as the time constant of the circuit:\r\n",
        "\r\n",
        "$$ \\tau \\frac{dU_{\\rm mem}}{dt} = -U_{\\rm mem} + RI_{\\rm in}(t)$$\r\n",
        "\r\n",
        "The passive membrane is therefore described by a linear differential equation.\r\n",
        "\r\n",
        "For a derivative of a function to be of the same form as the original function, i.e., $\\frac{dU_{\\rm mem}}{dt} \\propto U_{\\rm mem}$, this implies the solution is exponential with a time constant $\\tau$.\r\n",
        "\r\n",
        "Say the neuron starts at some value $U_{0}$ with no further input, i.e., $I_{\\rm in}(t)=0$. The solution of the linear differential equation is:\r\n",
        "\r\n",
        "$$U_{\\rm mem} = U_0e^{-\\frac{t}{\\tau}}$$\r\n",
        "\r\n",
        "\r\n",
        "<center>\r\n",
        "<img src='https://github.com/jeshraghian/snntorch/blob/master/docs/_static/img/examples/tutorial2/2_4_RCmembrane.png?raw=true' width=\"800\">\r\n",
        "</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rTXS_aSmRs-3"
      },
      "source": [
        "## 1.3 Lapicque's LIF Neuron Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jt2q6tZiWkgT"
      },
      "source": [
        "This similarity between nerve membranes and RC circuits was observed by [Louis Lapicque in 1907](https://core.ac.uk/download/pdf/21172797.pdf). He stimulated the nerve fiber of a frog with a brief electrical pulse, and found that membranes could be approximated as a capacitor with a leakage. We pay homage to his findings by naming the basic LIF neuron model in snnTorch after him. \r\n",
        "\r\n",
        "Now it's time to generate this result."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WtveAGG0zE0n"
      },
      "source": [
        "### 1.3.1 Without Stimulus"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "um1s01gTzUC0"
      },
      "source": [
        "First, install snnTorch and then import the libraries needed to run Lapicque's neuron model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7U6p-7u24LWw",
        "outputId": "0a401a88-23a0-436c-9811-743e051c9d23",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install snntorch"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting snntorch\n",
            "  Downloading https://files.pythonhosted.org/packages/ba/b5/57913069b3d8d5e49e1d5c73382747c577c384321f9250c112883c089656/snntorch-0.2.3-py2.py3-none-any.whl\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from snntorch) (1.1.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from snntorch) (3.2.2)\n",
            "Collecting celluloid\n",
            "  Downloading https://files.pythonhosted.org/packages/60/a7/7fbe80721c6f1b7370c4e50c77abe31b4d5cfeb58873d4d32f48ae5a0bae/celluloid-0.2.0-py3-none-any.whl\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from snntorch) (1.19.5)\n",
            "Requirement already satisfied: torch>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from snntorch) (1.8.0+cu101)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->snntorch) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->snntorch) (2018.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->snntorch) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->snntorch) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->snntorch) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.2.0->snntorch) (3.7.4.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->snntorch) (1.15.0)\n",
            "Installing collected packages: celluloid, snntorch\n",
            "Successfully installed celluloid-0.2.0 snntorch-0.2.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUyODsBtWkAG"
      },
      "source": [
        "import snntorch as snn\r\n",
        "import torch\r\n",
        "import numpy as np"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zpgNEbizd8s"
      },
      "source": [
        "The membrane potential has a time constant $\\tau = RC$ associated with it. This can be recast into a decay rate $\\beta$ that specifies the ratio of membrane between subsequent time steps:\r\n",
        "\r\n",
        "$$\\beta = \\frac{e^{-\\frac{1}{\\tau}}}{e^{-\\frac{0}{\\tau}}} = \\frac{e^{-\\frac{2}{\\tau}}}{e^{-\\frac{1}{\\tau}}} = \\frac{e^{-\\frac{3}{\\tau}}}{e^{-\\frac{2}{\\tau}}}=~~...$$\r\n",
        "$$\\implies \\beta = e^{-\\frac{1}{\\tau}}$$\r\n",
        "\r\n",
        "Setting $\\tau = 5 \\implies \\beta \\approx 0.82$:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohshwOCU6Vbm",
        "outputId": "1574b56e-cd24-40ab-99ec-075831f572c6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# RC time constant\r\n",
        "tau_mem = 5\r\n",
        "\r\n",
        "# decay p/time step\r\n",
        "beta = float(np.exp(-1/tau_mem))\r\n",
        "\r\n",
        "print(f\"beta: {beta}\")"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "beta: 0.8187307530779818\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9RH1cYmXOvm"
      },
      "source": [
        "# Number of time steps to simulate\r\n",
        "num_steps = 50"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qi5EnND98cz3"
      },
      "source": [
        "Instantiating Lapicque's neuron only requires the following line of code:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wI2Nahsg8d-t"
      },
      "source": [
        "# leaky integrate and fire neuron\r\n",
        "lif10 = snn.Stein(0.5, 0.4)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qw7p0qbbAW4h",
        "outputId": "c8737b80-ba80-437d-9113-31022b6f12ad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "lif10.threshold"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kuytxXet8lc9"
      },
      "source": [
        "To use this neuron: \r\n",
        "\r\n",
        "**Inputs**\r\n",
        "* `spk_in`: each element of $I_{\\rm in}$, which are all `0` for now, is sequentially passed as an input\r\n",
        "* `mem`: the membrane potential at the present time $t$ is also passed as input. Initialize it arbitrarily as $U_0 = 0.9$.\r\n",
        "\r\n",
        "**Outputs**\r\n",
        "* `spk_out`: output spike $S_{\\rm out}[t+1]$ at the next time step\r\n",
        "* `mem`: membrane potential $U_{\\rm mem}[t+1]$ at the next time step\r\n",
        "\r\n",
        "These all need to be of type `torch.Tensor`.\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_0O1Q3Y9KgM"
      },
      "source": [
        "# Initialize hidden states, input, and output\r\n",
        "mem = torch.ones(1) * 0.9  # membrane potential of 0.9 at t=0\r\n",
        "spk_in = torch.zeros(num_steps)  # input is 0 for all t \r\n",
        "spk_out = torch.zeros(1)  # neuron needs somewhere to sequentially dump its output spikes"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CEuNHsN8-67"
      },
      "source": [
        "These values are only for the initial time step $t=0$. We'd like to watch the evolution of `mem` over time. The list `mem_rec` is initialized to record these values at every time step."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUCxQBTQ9d_P"
      },
      "source": [
        "# Initialize somewhere to store recordings of membrane potential\r\n",
        "mem_rec = [mem]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4TxVFaV9uf6"
      },
      "source": [
        "Now it's time to run a simulation! Here's what's going to happen with our neuron model, `lif1`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6GeMMiU8kc4",
        "outputId": "866c7a92-f3ce-46b6-e2f3-b79a6f05316a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "# pass updated value of mem and spk_in[step]=0 at every time step\r\n",
        "for step in range(num_steps):\r\n",
        "  spk_out, mem = lif1(spk_in[step], mem)\r\n",
        "\r\n",
        "  # Store recordings of membrane potential\r\n",
        "  mem_rec.append(mem)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-248543c7341a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# pass updated value of mem and spk_in[step]=0 at every time step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mspk_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlif1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspk_in\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;31m# Store recordings of membrane potential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'lif1' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PYWhh7idiS9t"
      },
      "source": [
        "# Conclusion\r\n",
        "Now you should understand how to build populations of LIF neuron models to perform feedforward processing of various inputs. \r\n",
        "\r\n",
        "For reference, the documentation [can be found here](https://snntorch.readthedocs.io/en/latest/snntorch.html).\r\n",
        "\r\n",
        "In the next tutorial, you will learn how to train these networks to classify spiking and static MNIST datasets. In fact, if you already have a basic grasp of PyTorch, the next tutorial will be quite trivial."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9D8Ce5-QiYEA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}