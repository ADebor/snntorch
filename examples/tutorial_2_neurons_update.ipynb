{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled17.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPSWhAXrcAQe2QXcvZKUCgl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jeshraghian/snntorch/blob/tutorials/examples/tutorial_2_neurons_update.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HzIQBw28NL8h"
      },
      "source": [
        "<img src='https://github.com/jeshraghian/snntorch/blob/master/docs/_static/img/snntorch_alpha_w.png?raw=true' width=\"400\">\r\n",
        "\r\n",
        "# snnTorch - Neuronal Dynamics with ``snntorch``\r\n",
        "## Tutorial 2\r\n",
        "### By Jason K. Eshraghian (www.jasoneshraghian.com)\r\n",
        "\r\n",
        "<a href=\"https://colab.research.google.com/github/jeshraghian/snntorch/blob/tutorials/examples/tutorial_2_neurons.ipynb\">\r\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\r\n",
        "</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ep_Qv7kzNOz6"
      },
      "source": [
        "# Introduction\r\n",
        "In this tutorial, you will:\r\n",
        "* Learn the basics of a leaky integrate-and-fire (LIF)\r\n",
        "* Use snnTorch to implement variations of the LIF model: \r\n",
        "  * Lapicque's LIF neuron model\r\n",
        "  * Stein's neuron model\r\n",
        "  * 0$^{th}$ Order Spike Response Model\r\n",
        "<!-- * Plot the output behavior of the neurons -->\r\n",
        "<!-- * Interpret the computational graph of a spiking neuron -->\r\n",
        "<!-- * Automatically initialize the hidden states of the neurons [keep in tute, but delete explanation]? -->\r\n",
        "* Implement a feedforward spiking neural network\r\n",
        "\r\n",
        ">Part of this tutorial was inspired by the book [*Neuronal Dynamics:\r\n",
        "From single neurons to networks and models of cognition*](https://neuronaldynamics.epfl.ch/index.html) by\r\n",
        "Wulfram Gerstner, Werner M. Kistler, Richard Naud and Liam Paninski.\r\n",
        "\r\n",
        "If running in Google Colab:\r\n",
        "* You may connect to GPU by checking `Runtime` > `Change runtime type` > `Hardware accelerator: GPU`\r\n",
        "* Next, install the latest PyPi distribution of snnTorch by clicking into the following cell and pressing `Shift+Enter`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SPQITvDuNNJg",
        "outputId": "d8c161bc-b5b7-417c-8ef2-a0dd7f6d8704"
      },
      "source": [
        "!pip install snntorch"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting snntorch\n",
            "  Downloading https://files.pythonhosted.org/packages/96/62/af42377ae9c7266bc1bdf63b3b58b9663a60a8e3510fb96d22b76e7ffb80/snntorch-0.2.1-py2.py3-none-any.whl\n",
            "Collecting celluloid\n",
            "  Downloading https://files.pythonhosted.org/packages/60/a7/7fbe80721c6f1b7370c4e50c77abe31b4d5cfeb58873d4d32f48ae5a0bae/celluloid-0.2.0-py3-none-any.whl\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from snntorch) (1.1.5)\n",
            "Requirement already satisfied: torch>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from snntorch) (1.8.0+cu101)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from snntorch) (1.19.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from snntorch) (3.2.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->snntorch) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->snntorch) (2.8.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.2.0->snntorch) (3.7.4.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->snntorch) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->snntorch) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->snntorch) (1.3.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->snntorch) (1.15.0)\n",
            "Installing collected packages: celluloid, snntorch\n",
            "Successfully installed celluloid-0.2.0 snntorch-0.2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xmTt5dvyXNNy"
      },
      "source": [
        "# 1. The Spectrum of Neuron Models\r\n",
        "A large variety of neuron models are out there, ranging from biophysically accurate models (i.e., the Hodgkin-Huxley models) to the extremely simple artificial neuron that pervades all facets of modern deep learning.\r\n",
        "\r\n",
        "**Hodgkin-Huxley Neuron Models**$-$While biophysical models can reproduce electrophysiological results with a high degree of accuracy, their complexity makes them difficult to use. We expect this to change as more rigorous theories of how neurons contribute to higher-order behaviors in the brain are uncovered.\r\n",
        "\r\n",
        "**Artificial Neuron Model**$-$On the other end of the spectrum is the artificial neuron. The inputs are multiplied by their corresponding weights and passed through an activation function. This simplification has enabled deep learning researchers to perform incredible feats in computer vision, natural language processing, and many other machine learning-domain tasks.\r\n",
        "\r\n",
        "**Leaky Integrate-and-Fire Neuron Models**$-$Somewhere in the middle of the divide lies the leaky integrate-and-fire (LIF) neuron model. It takes the sum of weighted inputs, much like the artificial neuron. But rather than passing it directly to an activation function, it will integrate the input over time with a leakage, much like an RC circuit. If the integrated value exceeds a threshold, then the LIF neuron will emit a voltage spike. The LIF neuron abstracts away the shape and profile of the output spike; it is simply treated as a discrete event. As a result, information is not stored within the spike, but rather the timing (or frequency) of spikes. Simple spiking neuron models have produced much insight into the neural code, memory, network dynamics, and more recently, deep learning. The LIF neuron sits in the sweet spot between biological plausibility and practicality. \r\n",
        "\r\n",
        "<center>\r\n",
        "<img src='https://github.com/jeshraghian/snntorch/blob/master/docs/_static/img/examples/tutorial2/2_1_neuronmodels.png?raw=true' width=\"1000\">\r\n",
        "</center>\r\n",
        "\r\n",
        "<!-- Researchers might spend their entire lives dedicated to developing neuron models. Some of these models are straightforward extensions of the HH and LIF models, while other models find completely different applications, such as in neuropharmocology. -->\r\n",
        "\r\n",
        "The different versions of the LIF model each have their own dynamics and use-cases. snnTorch currently supports three types of LIF neurons:\r\n",
        "* Lapicque's RC model: ``snntorch.Lapicque``\r\n",
        "* Stein's neuron model: ``snntorch.Stein``\r\n",
        "* 0$^{th}$ Order Spike Response Model: ``snntorch.SRM0``\r\n",
        "\r\n",
        "Before learning how to use them, let's understand how to construct a simple LIF neuron model.\r\n",
        "\r\n",
        "<!-- In general, the most obvious difference is that the SRM0 model incorporates a delay between the input and output. When an input spike arrives at an SRM0 neuron, the membrane potential will increase over a finite time. If an output spike were to be triggered, it would experience a delay with respect to the input. On the other hand, Stein's model allows for an instantaneous rise of membrane potential. We'll dig into where these might be useful shortly. -->\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nea8oBorr_KZ"
      },
      "source": [
        "# 1. The Leaky Integrate-and-Fire Neuron Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YKsrN5feQ2Dz"
      },
      "source": [
        "## 1.1 Spiking Neurons: Intuition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YGStnfjzsGKb"
      },
      "source": [
        "A neuron might be connected to 1,000 $-$ 10,000 other neurons. If one neuron spikes, all of these downhill neurons will feel it. But what determines whether a neuron spikes in the first place? The past century of experiments demonstrate that if a neuron experiences *sufficient* stimulus at its input, then we might expect it to become excited and fire its own spike. \r\n",
        "\r\n",
        "Where does this stimulus come from? It could be from\r\n",
        "* the sensory periphery, \r\n",
        "* an invasive electrode artificially stimulating the neuron, or in most cases,\r\n",
        "* from other pre-synaptic neurons. \r\n",
        "\r\n",
        "<center>\r\n",
        "<img src='https://github.com/jeshraghian/snntorch/blob/master/docs/_static/img/examples/tutorial2/2_2_intuition.png?raw=true' width=\"800\">\r\n",
        "</center>\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TaVTRojJ2Dl_"
      },
      "source": [
        "Given that these spikes are very short bursts of electrical activity, it is quite unlikely for all input spikes to arrive at the neuron body in precise unison. This indicates the presence of temporal dynamics that 'sustain' the input spikes, kind of like a delay.\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l44jI7A2ReB_"
      },
      "source": [
        "## 1.2 The Passive Membrane"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Od5tfXv6_wcq"
      },
      "source": [
        "Like all cells, a neuron is surrounded by a thin membrane. This membrane is a lipid bilayer that insulates the conductive saline solution within the neuron from the extracellular medium. Electrically, the two conductors separated by an insulator is a capacitor. \r\n",
        "\r\n",
        "Another function of this membrane is to control what goes in and out of this cell (e.g., ions such as Na$^+$). The membrane is usually impermeable to ions which blocks them from entering and exiting the neuron body. But there are specific channels in the membrane that are triggered to open by injecting current into the neuron. This charge movement is electrically modelled by a resistor.\r\n",
        "\r\n",
        "<center>\r\n",
        "<img src='https://github.com/jeshraghian/snntorch/blob/master/docs/_static/img/examples/tutorial2/2_3_passivemembrane.png?raw=true' width=\"800\">\r\n",
        "</center>\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wT_S4b4HL2ir"
      },
      "source": [
        "Now say some arbitrary time-varying current $I_{\\rm in}(t)$ is injected into the neuron, be it via electrical stimulation or from other neurons. The total current in the circuit is conserved, so:\r\n",
        "\r\n",
        "$$I_{\\rm in}(t) = I_{R} + I_{C}$$\r\n",
        "\r\n",
        "From Ohm's Law, the membrane potential measured between the inside and outside of the neuron $U_{\\rm mem}$ is proportional to the current through the resistor:\r\n",
        "\r\n",
        "$$I_{R} = \\frac{U_{\\rm mem}}{R}$$\r\n",
        "\r\n",
        "The capacitance is a proportionality constant between the charge stored on the capacitor $Q$ and $U_{\\rm mem}$:\r\n",
        "\r\n",
        "\r\n",
        "$$Q = CU_{\\rm mem}$$\r\n",
        "\r\n",
        "The rate of change of charge gives the capacitive current:\r\n",
        "\r\n",
        "$$\\frac{dQ}{dt}=I_C = C\\frac{dU_{\\rm mem}}{dt}$$\r\n",
        "\r\n",
        "Therefore:\r\n",
        "\r\n",
        "$$I_{\\rm in}(t) = \\frac{U_{\\rm mem}}{R} + C\\frac{dU_{\\rm mem}}{dt}$$\r\n",
        "$$\\implies RC \\frac{dU_{\\rm mem}}{dt} = -U_{\\rm mem} + RI_{\\rm in}(t)$$\r\n",
        "\r\n",
        "The right hand side of the equation is **\\[Voltage]**. On the left hand side of the equation, the term $\\frac{dU_{\\rm mem}}{dt}$ is of units **\\[Voltage/Time]**. To equate it to a voltage, $RC$ must be of unit **\\[Time]**. We refer to $\\tau = RC$ as the time constant of the circuit:\r\n",
        "\r\n",
        "$$ \\tau \\frac{dU_{\\rm mem}}{dt} = -U_{\\rm mem} + RI_{\\rm in}(t)$$\r\n",
        "\r\n",
        "The passive membrane is therefore described by a linear differential equation.\r\n",
        "\r\n",
        "For a derivative of a function to be of the same form as the original function, i.e., $\\frac{dU_{\\rm mem}}{dt} \\propto U_{\\rm mem}$, this implies the solution is exponential with a time constant $\\tau$. \r\n",
        "\r\n",
        "Say the neuron starts at some value $U_{0}$. In the absence of any input, i.e., $I_{\\rm in}(t)=0$, the solution of the linear differential equation is:\r\n",
        "\r\n",
        "$$U_{\\rm mem} = U_0e^{-\\frac{t}{\\tau}}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Zm4n2YTR4Cg"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rTXS_aSmRs-3"
      },
      "source": [
        "## 1.3 Lapicque's LIF neuron model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9RH1cYmXOvm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PYWhh7idiS9t"
      },
      "source": [
        "# Conclusion\r\n",
        "Now you should understand how to build populations of LIF neuron models to perform feedforward processing of various inputs. \r\n",
        "\r\n",
        "For reference, the documentation [can be found here](https://snntorch.readthedocs.io/en/latest/snntorch.html).\r\n",
        "\r\n",
        "In the next tutorial, you will learn how to train these networks to classify spiking and static MNIST datasets. In fact, if you already have a basic grasp of PyTorch, the next tutorial will be quite trivial."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9D8Ce5-QiYEA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}