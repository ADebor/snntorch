{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spike Train Generation\n",
    "## 1. MNIST Conversion to Spike Train\n",
    "### 1.1. Import packages and setup environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Note to self: Clear previous versions of snntorch\n",
    "#!rm -rf snntorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "#!git clone https://Username:Password@github.com/username/repository.git"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Importing `os`, `sys`, and modifying paths are only needed while this notebook is under development.\n",
    "These can be safely removed once distributed on PyPi."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Note to self: when running locally, I need to change directory to the following path\n",
    "os.chdir(\"C:\\\\Users\\\\Jason\\\\Dropbox\\\\repos\\\\snntorch\")\n",
    "\n",
    "# When running on Colab, use this line to add it to the search path:\n",
    "sys.path.insert(0, '/content/snntorch')\n",
    "\n",
    "import snntorch as snn\n",
    "from snntorch.spikevision import datamod, spikegen\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the configuration file which contains information about the dataset.\n",
    "\n",
    "The first argument is the dimensions of the dataset. `channels` is entered as the second argument.\n",
    "\n",
    "`split` is used to assign data from the training to the the validation set.\n",
    "*E.g., for a split of 0.2, the validation set will be made up of 20% of the train set.*\n",
    "\n",
    "`subset` is used to partition the training and test sets down by the given factor.\n",
    "*E.g., for a subset of 100, a training set of 60,000 will be reduced to 600.*\n",
    "\n",
    "`num_classes` is the number of output classes (10 for MNIST).\n",
    "\n",
    " `T` is the number of time steps to be simulated.\n",
    "\n",
    "`data_path` is the target directory for downloading the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "config = snn.utils.Configuration([28,28], channels=1, batch_size=100, split=0.1, subset=100, num_classes=10, T=1000,\n",
    "                           data_path='/data/mnist')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Download Dataset\n",
    "\n",
    "Note that `mnist_val` is the same as `mnist_train`.\n",
    "This allows us to retain the `data` and `target` attributes which would otherwise be lost had we used `random_split`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Define a transform\n",
    "transform = transforms.Compose([\n",
    "            transforms.Resize(config.input_size),\n",
    "            transforms.Grayscale(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0,), (1,))])\n",
    "\n",
    "mnist_train = datasets.MNIST(config.data_path, train=True, download=True, transform=transform)\n",
    "mnist_val = datasets.MNIST(config.data_path, train=True, download=True, transform=transform)\n",
    "mnist_test = datasets.MNIST(config.data_path, train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Create train/validation split using the value in `config.split`.\n",
    "\n",
    "`spikevision` is a package within `snntorch` containing useful functions for modifying the data set.\n",
    "These functions are in the module `datamod`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "mnist_train, mnist_val = datamod.valid_split(mnist_train, mnist_val, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Reduce training, validation and test sets to smaller subsets for faster processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "mnist_train = datamod.data_subset(mnist_train, config)\n",
    "mnist_val = datamod.data_subset(mnist_val, config)\n",
    "mnist_test = datamod.data_subset(mnist_test, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "As a sanity check, let's take a look at the length of each of our datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of mnist_train is 540\n",
      "The size of mnist_val is 60\n",
      "The size of mnist_test is 100\n"
     ]
    }
   ],
   "source": [
    "print(f\"The size of mnist_train is {len(mnist_train)}\")\n",
    "print(f\"The size of mnist_val is {len(mnist_val)}\")\n",
    "print(f\"The size of mnist_test is {len(mnist_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 1.3 Create Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(mnist_train, batch_size=config.batch_size, shuffle=True)\n",
    "val_loader = DataLoader(mnist_val, batch_size=config.batch_size, shuffle=True)\n",
    "test_loader = DataLoader(mnist_test, batch_size=config.batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 1.4 Spike Train Generation\n",
    "The pixels from each image are passed as the mean of a Bernoulli distribution to generate a Poisson spike train.\n",
    "This is done one minibatch at a time. `gain` is used as a factor to alter the mean, and is clipped between `1` and `0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Create a generator instead of iterator\n",
    "data = iter(train_loader)\n",
    "data_it, targets_it = next(data)\n",
    "data_it = data_it.to(device)\n",
    "targets_it = targets_it.to(device)\n",
    "\n",
    "# Spiking Data\n",
    "spike_data, spike_targets = spikegen.spike_conversion(data_it, targets_it, config, gain=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### 1.4.1 Visualising Data\n",
    "##### 1.4.1.1 Animations\n",
    "The `spikeplot` module contains useful functions for visualising spiking data. Let's index into one sample from\n",
    "`spike_data`, where it is of dimensions [T x B x C x W x H], and must be reduced to [T x W x H]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Requested MovieWriter (ffmpeg) not available",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-10-e32869773dd7>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m()\u001B[0m\n\u001B[0;32m     10\u001B[0m \u001B[0mspike_data_visualizer\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mspike_data\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     11\u001B[0m \u001B[0mdata_sample\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mspikeplot\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mspike_animator\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mspike_data_visualizer\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mx\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m28\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m28\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mT\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m100\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 12\u001B[1;33m \u001B[0mHTML\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata_sample\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto_html5_video\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     13\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     14\u001B[0m \u001B[1;31m# HTML required installation of ffmpeg package on PyCharm.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\animation.py\u001B[0m in \u001B[0;36mto_html5_video\u001B[1;34m(self, embed_limit)\u001B[0m\n\u001B[0;32m   1314\u001B[0m                 \u001B[1;31m# We create a writer manually so that we can get the\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1315\u001B[0m                 \u001B[1;31m# appropriate size for the tag\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1316\u001B[1;33m                 \u001B[0mWriter\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mwriters\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mmpl\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrcParams\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'animation.writer'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1317\u001B[0m                 writer = Writer(codec='h264',\n\u001B[0;32m   1318\u001B[0m                                 \u001B[0mbitrate\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mmpl\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrcParams\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'animation.bitrate'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\animation.py\u001B[0m in \u001B[0;36m__getitem__\u001B[1;34m(self, name)\u001B[0m\n\u001B[0;32m    164\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mis_available\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    165\u001B[0m             \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_registered\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 166\u001B[1;33m         \u001B[1;32mraise\u001B[0m \u001B[0mRuntimeError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34mf\"Requested MovieWriter ({name}) not available\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    167\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    168\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: Requested MovieWriter (ffmpeg) not available"
     ]
    }
   ],
   "source": [
    "# Note to Self: matplotlib.use(\"TkAgg\") is only needed when running this notebook in PyCharm:\n",
    "# import matplotlib as plt\n",
    "# import matplotlib; matplotlib.use(\"TkAgg\")\n",
    "\n",
    "from snntorch import spikeplot\n",
    "from IPython.display import HTML\n",
    "\n",
    "\n",
    "spike_data_visualizer = spike_data[:,0,0]\n",
    "data_sample = spikeplot.spike_animator(spike_data_visualizer, x=28, y=28, T=100)\n",
    "HTML(data_sample.to_html5_video())\n",
    "\n",
    "# HTML required installation of ffmpeg package on PyCharm.\n",
    "#plt.show()\n",
    "\n",
    "# To save as gif, uncomment the following line:\n",
    "# data_sample.save(\"spike_plot.gif\", writer='imagemagick')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "And the associated label can be indexed as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The target is: 6\n"
     ]
    }
   ],
   "source": [
    "print(f\"The target is: {spikegen.from_one_hot(spike_targets[0][0])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "As a matter of interest, let's do that again but with 25% of the gain for increased sparsity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spikeplot' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-14-2996c352ebfe>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[0mspike_data\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mspike_targets\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mspikegen\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mspike_conversion\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata_it\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtargets_it\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mconfig\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mgain\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m0.25\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[0mspike_data_visualizer\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mspike_data\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 4\u001B[1;33m \u001B[0mdata_sample\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mspikeplot\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mspike_animator\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mspike_data_visualizer\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mx\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m28\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m28\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mT\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m100\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      5\u001B[0m \u001B[0mHTML\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata_sample\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto_html5_video\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'spikeplot' is not defined"
     ]
    }
   ],
   "source": [
    "spike_data, spike_targets = spikegen.spike_conversion(data_it, targets_it, config, gain=0.25)\n",
    "spike_data_visualizer = spike_data[:,0,0]\n",
    "data_sample = spikeplot.spike_animator(spike_data_visualizer, x=28, y=28, T=100)\n",
    "HTML(data_sample.to_html5_video())\n",
    "#print(f\"The target is: {spikegen.from_one_hot(spike_targets[0][0])}\")\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now let's average the spikes out over time and reconstruct the input image."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(spike_data_visualizer.mean(axis=0).reshape((28,-1)).cpu())\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "##### 1.4.1.2 Spike Raster Plots\n",
    "Let's look at a raster plot of the input spikes by calling `spikeplot.raster`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1000x500 with 1 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "spike_data_visualizer = spike_data[:,0,0]\n",
    "spike_data_visualizer = spike_data_visualizer.reshape((config.T, -1))\n",
    "\n",
    "# raster plot\n",
    "fig = plt.figure(facecolor=\"w\", figsize=(10, 5))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "# Note: if the following line doesn't work on Colab, update PIL and restart runtime\n",
    "# !pip install Pillow==5.3.0\n",
    "spikeplot.raster(data=spike_data_visualizer, ax=ax, s=1, c=\"black\")\n",
    "\n",
    "plt.title(\"Input Layer\")\n",
    "plt.xlabel(\"Time step\")\n",
    "plt.ylabel(\"Neuron Number\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can also index into one single neuron:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "spikeplot.raster(data=spike_data_visualizer[:,1], ax=ax, s=100, c=\"black\", marker=\"|\")\n",
    "plt.title(\"Input Neuron\")\n",
    "plt.xlabel(\"Time step\")\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.0 LIF Neuron: 3-Factor Learning Rule\n",
    "### 2.1 LIF Neuron: Voltage & Current Dependent\n",
    "### 2.2 LIF Neuron w/Alpha Function -- low priority\n",
    "\n",
    "### Update plot to handle membrane potentials"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "There is another function we can call to generate a spike train.\n",
    "Unsurprisingly, `spikegen.spike_train`."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create a random spike train\n",
    "Sin = torch.FloatTensor(spikegen.spike_train(N_in=10, data_config=config, rate=0.5))\n",
    "\n",
    "# raster plot\n",
    "fig = plt.figure(facecolor=\"w\", figsize=(10, 5))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "spikeplot.raster(data=Sin, ax=ax, s=0.2, c=\"black\")\n",
    "\n",
    "plt.title(\"Input Layer\")\n",
    "plt.xlabel(\"Time step\")\n",
    "plt.ylabel(\"Neuron Number\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "9QXsrr6Mp5e_",
    "1EWDw3bip8Ie",
    "vFM8UV9CreIX",
    "xXkTAJ9ws1Y6",
    "OgkWg605tE1y",
    "OBt0WDzyujnk",
    "xC96eesMqYo-",
    "mszPTrYOluym",
    "VTHK-wAWV57B"
   ],
   "name": "Copy of quantAwareTrain.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}