{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "Copy of quantAwareTrain.ipynb",
   "provenance": [],
   "collapsed_sections": [
    "9QXsrr6Mp5e_",
    "1EWDw3bip8Ie",
    "vFM8UV9CreIX",
    "xXkTAJ9ws1Y6",
    "OgkWg605tE1y",
    "OBt0WDzyujnk",
    "xC96eesMqYo-",
    "mszPTrYOluym",
    "VTHK-wAWV57B"
   ]
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Spike Train Generation\n",
    "## 1. MNIST Conversion to Spike Train\n",
    "### 1.1. Import packages and setup environment"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# Note to self: from snntorch import utils is not needed as that is in __init__\n",
    "\n",
    "import torch\n",
    "import os\n",
    "\n",
    "# Note to self: when running from a notebook, I need to change directory to the following path\n",
    "os.chdir(\"C:\\\\Users\\\\Jason\\\\Dropbox\\\\repos\\\\snntorch\")\n",
    "\n",
    "import snntorch as snn\n",
    "from snntorch.spikevision import datamod, spikegen\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Initialize the configuration file which contains information about the dataset.\n",
    "\n",
    "The first input refers to the first two dataset dimensions. `channels` is the third dimension (i.e., depth).\n",
    "\n",
    "`split` can be used to assign data from the training to the the validation set.\n",
    "*E.g., for a split of 0.2, the validation set will be made up of 20% of the train set.*\n",
    "\n",
    "`subset` is used to partition the training and test sets down by the given factor.\n",
    "*E.g., for a subset of 100, a training set of 60,000 will be reduced to 600.*\n",
    "\n",
    "`num_classes` is the number of output classes (10 for MNIST).\n",
    "\n",
    " `T` is the number of time steps to be simulated.\n",
    "\n",
    " Finally, `data_path` is the directory to which your training set will be downloaded to, if using torchvision."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "config = snn.utils.Configuration([28,28], channels=1, batch_size=100, split=0.1, subset=100, num_classes=10, T=1000,\n",
    "                           data_path='/data/mnist')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.2 Download Dataset\n",
    "\n",
    "Note that we are creating a dataset `mnist_val` which is equivalent to `mnist_train`.\n",
    "This allows us to retain the `data` and `target` attributes which would otherwise be lost had we used `random_split`."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Define a transform\n",
    "transform = transforms.Compose([\n",
    "            transforms.Resize(config.input_size),\n",
    "            transforms.Grayscale(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0,), (1,))])\n",
    "\n",
    "mnist_train = datasets.MNIST(config.data_path, train=True, download=True, transform=transform)\n",
    "mnist_val = datasets.MNIST(config.data_path, train=True, download=True, transform=transform)\n",
    "mnist_test = datasets.MNIST(config.data_path, train=False, download=True, transform=transform)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create train/validation split using the value in `config.split`.\n",
    "\n",
    "`spikevision` is a subpackage within `snntorch` containing useful modules for modifying the data set.\n",
    "Many such functions are called from the package `datamod`."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from snntorch.spikevision import datamod\n",
    "\n",
    "mnist_train, mnist_val = datamod.valid_split(mnist_train, mnist_val, config)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Reduce training, validation and test sets to smaller subsets as defined in `config.subset`."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "mnist_train = datamod.data_subset(mnist_train, config)\n",
    "mnist_val = datamod.data_subset(mnist_val, config)\n",
    "mnist_test = datamod.data_subset(mnist_test, config)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As a quick sanity check, let's take a look at the length of each of our datasets:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of mnist_train is 540\n",
      "The size of mnist_val is 60\n",
      "The size of mnist_test is 100\n"
     ]
    }
   ],
   "source": [
    "print(f\"The size of mnist_train is {len(mnist_train)}\")\n",
    "print(f\"The size of mnist_val is {len(mnist_val)}\")\n",
    "print(f\"The size of mnist_test is {len(mnist_test)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.3 Create Dataloaders"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Note to self: after each dataloader object, append \".to(device)\"\n",
    "train_loader = DataLoader(mnist_train, batch_size=config.batch_size, shuffle=True)\n",
    "val_loader = DataLoader(mnist_val, batch_size=config.batch_size, shuffle=True)\n",
    "test_loader = DataLoader(mnist_test, batch_size=config.batch_size, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.4 Spike Train Generation\n",
    "We now need to convert static images from MNIST into a spike train. Ideally, this would be done in one single batch.\n",
    "But this will often exceed memory capacity as the size of a dataset would be multiplied by the number of time steps.\n",
    "*E.g., a 45 MB MNIST dataset simulated for T=1,000 time steps would be 45GB.*\n",
    "\n",
    "To avoid this issue, minibatches of spikes must be re-calculated every time they are called."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "data = iter(train_loader)\n",
    "data_it, targets_it = next(data)\n",
    "\n",
    "# Spiking Data --------- should calculate this on cuda, test on colab.\n",
    "spike_data, spike_targets = spikegen.spike_conversion(data_it, targets_it, config)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1.4.1 Visualising Data\n",
    "The `spikeplot` module contains useful functions for visualising spiking data. Let's index into one sample from\n",
    "`spike_data`, where it is of dimensions [T x B x C x W x H], and must be reduced to [T x W x H]."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "from snntorch import spikeplot\n",
    "# Note to Self: I only needed matplotlib.use(\"TkAgg\") for use in PyCharm.\n",
    "import matplotlib; matplotlib.use(\"TkAgg\")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "spike_data_visualizer = spike_data[:,0,0]\n",
    "data_sample = spikeplot.spike_animator(spike_data_visualizer, x=28, y=28, T=100)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# If the above code doesn't work in Colab, then modify spikeplot to the following. Need to test:\n",
    "# from IPython.display import HTML\n",
    "# plt.close(fig)\n",
    "# print(spike_targets[0][0])\n",
    "# HTML(anim.to_html5_video())\n",
    "\n",
    "#however, HTML required installation of ffmpeg package. Not ideal."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "And the associated label can be indexed as follows:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The target is: 8\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(f\"The target is: {np.argmax(spike_targets[0][:][0], axis=0)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As a matter of interest, let's do that again but with 25% of the gain for increased sparsity:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "spike_data, spike_targets = spikegen.spike_conversion(data_it, targets_it, config, gain=0.25)\n",
    "spike_data_visualizer = spike_data[:,0,0]\n",
    "data_sample = spikeplot.spike_animator(spike_data_visualizer, x=28, y=28, T=100)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### To-do: 1) append \".to(device)\" to dataloaders\n",
    "#### To-do: 2) include functionality for the following datasets, as we will need to benchmark:\n",
    "##### a) CIFAR-10 converted to spikes\n",
    "##### b) NMNIST\n",
    "##### c) N-CIFAR-10?\n",
    "##### d) DVS Gesture\n",
    "##### d) EEG from Enea's Frontiers paper\n",
    "##### e)\n",
    "\n",
    "### 2.0 LIF Neuron & Architecture"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ]
}