{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spike Train Generation\n",
    "## 1. MNIST Conversion to Spike Train\n",
    "### 1.1. Import packages and setup environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Note to self: from snntorch import utils is not needed as that is in __init__\n",
    "\n",
    "import torch\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Note to self: when running locally, I need to change directory to the following path\n",
    "os.chdir(\"C:\\\\Users\\\\Jason\\\\Dropbox\\\\repos\\\\snntorch\")\n",
    "\n",
    "# when running on colab, use this line to add it to the search path:\n",
    "sys.path.insert(0, '/content/snntorch')\n",
    "\n",
    "import snntorch as snn\n",
    "from snntorch.spikevision import datamod, spikegen\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the configuration file which contains information about the dataset.\n",
    "\n",
    "The first input refers to the first two dataset dimensions. `channels` is the third dimension (i.e., depth).\n",
    "\n",
    "`split` can be used to assign data from the training to the the validation set.\n",
    "*E.g., for a split of 0.2, the validation set will be made up of 20% of the train set.*\n",
    "\n",
    "`subset` is used to partition the training and test sets down by the given factor.\n",
    "*E.g., for a subset of 100, a training set of 60,000 will be reduced to 600.*\n",
    "\n",
    "`num_classes` is the number of output classes (10 for MNIST).\n",
    "\n",
    " `T` is the number of time steps to be simulated.\n",
    "\n",
    " Finally, `data_path` is the directory to which your training set will be downloaded to, if using torchvision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "config = snn.utils.Configuration([28,28], channels=1, batch_size=100, split=0.1, subset=100, num_classes=10, T=1000,\n",
    "                           data_path='/data/mnist')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Download Dataset\n",
    "\n",
    "Note that we are creating a dataset `mnist_val` which is equivalent to `mnist_train`.\n",
    "This allows us to retain the `data` and `target` attributes which would otherwise be lost had we used `random_split`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Define a transform\n",
    "transform = transforms.Compose([\n",
    "            transforms.Resize(config.input_size),\n",
    "            transforms.Grayscale(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0,), (1,))])\n",
    "\n",
    "mnist_train = datasets.MNIST(config.data_path, train=True, download=True, transform=transform)\n",
    "mnist_val = datasets.MNIST(config.data_path, train=True, download=True, transform=transform)\n",
    "mnist_test = datasets.MNIST(config.data_path, train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Create train/validation split using the value in `config.split`.\n",
    "\n",
    "`spikevision` is a subpackage within `snntorch` containing useful modules for modifying the data set.\n",
    "Many such functions are called from the package `datamod`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from snntorch.spikevision import datamod\n",
    "\n",
    "mnist_train, mnist_val = datamod.valid_split(mnist_train, mnist_val, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Reduce training, validation and test sets to smaller subsets as defined in `config.subset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "mnist_train = datamod.data_subset(mnist_train, config)\n",
    "mnist_val = datamod.data_subset(mnist_val, config)\n",
    "mnist_test = datamod.data_subset(mnist_test, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "As a quick sanity check, let's take a look at the length of each of our datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of mnist_train is 540\n",
      "The size of mnist_val is 60\n",
      "The size of mnist_test is 100\n"
     ]
    }
   ],
   "source": [
    "print(f\"The size of mnist_train is {len(mnist_train)}\")\n",
    "print(f\"The size of mnist_val is {len(mnist_val)}\")\n",
    "print(f\"The size of mnist_test is {len(mnist_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 1.3 Create Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Note to self: after each dataloader object, append \".to(device)\"\n",
    "train_loader = DataLoader(mnist_train, batch_size=config.batch_size, shuffle=True)\n",
    "val_loader = DataLoader(mnist_val, batch_size=config.batch_size, shuffle=True)\n",
    "test_loader = DataLoader(mnist_test, batch_size=config.batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 1.4 Spike Train Generation\n",
    "We now need to convert static images from MNIST into a spike train. Ideally, this would be done in one single batch.\n",
    "But this will often exceed memory capacity as the size of a dataset would be multiplied by the number of time steps.\n",
    "*E.g., a 45 MB MNIST dataset simulated for T=1,000 time steps would be 45GB.*\n",
    "\n",
    "To avoid this issue, minibatches of spikes must be re-calculated every time they are called."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data = iter(train_loader)\n",
    "data_it, targets_it = next(data)\n",
    "\n",
    "# Spiking Data --------- should calculate this on cuda, test on colab.\n",
    "spike_data, spike_targets = spikegen.spike_conversion(data_it, targets_it, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### 1.4.1 Visualising Data\n",
    "The `spikeplot` module contains useful functions for visualising spiking data. Let's index into one sample from\n",
    "`spike_data`, where it is of dimensions [T x B x C x W x H], and must be reduced to [T x W x H]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from snntorch import spikeplot\n",
    "# Note to Self: I only needed matplotlib.use(\"TkAgg\") for use in PyCharm.\n",
    "import matplotlib; matplotlib.use(\"TkAgg\")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "spike_data_visualizer = spike_data[:,0,0]\n",
    "data_sample = spikeplot.spike_animator(spike_data_visualizer, x=28, y=28, T=100)\n",
    "#plt.show()\n",
    "\n",
    "\n",
    "# If the above code doesn't work in Colab, then modify spikeplot to the following. Need to test:\n",
    "#from IPython.display import HTML\n",
    "#plt.close(fig)\n",
    "#print(spike_targets[0][0])\n",
    "#HTML(data_sample.to_html5_video())\n",
    "\n",
    "#however, HTML required installation of ffmpeg package. Not ideal.\n",
    "#### I should come up with a more general solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "And the associated label can be indexed as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The target is: 6\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(f\"The target is: {np.argmax(spike_targets[0][:][0], axis=0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "As a matter of interest, let's do that again but with 25% of the gain for increased sparsity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAADnCAYAAADl9EEgAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAADsklEQVR4nO3dwY3TYBhFUYxYZBNRAeVRRCpIEZRHBSib7H72I2eGIY5945yzjIUIi6tP4o1hGmN8AXq+bv0FgHnihChxQpQ4IUqcEPXtvYfHw9lf5cKDXa6nae5zlxOixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEqHf/DSGez+8/v+769T++/1zom3AvlxOixAlR4oQocUKUOCFKnBAlToiyc+6MnXI/XE6IEidEiROixAlR4oQocUKUOCHKzhnz0fuYH+2Y3ufcD5cTosQJUeKEKHFClDghSpwQJU6IsnPG3LszPnoHZT0uJ0SJE6LECVHihChxQpQ4IUqcEGXnXNmj39f0PuZ+uJwQJU6IEidEiROixAlR4oQocUKUOCFqGmPcfHg8nG8/ZJYfEuCzLtfTNPe5ywlR4oQocUKUOCFKnBAlTogSJ0R52Xphj94x7aivw+WEKHFClDghSpwQJU6IEidEiROi7Jwru3entGO+DpcTosQJUeKEKHFClDghSpwQJU6IsnMuzPuWLMXlhChxQpQ4IUqcECVOiBInRIkTouycC9v7jmnHXY/LCVHihChxQpQ4IUqcECVOiBInRNk5V1bfCevf75W4nBAlTogSJ0SJE6LECVHihChxQtQ0xrj58Hg4337IJrbeIbf+/ffocj1Nc5+7nBAlTogSJ0SJE6LECVHihChxQpT3ORd27w5Y3xHtqOtxOSFKnBAlTogSJ0SJE6LECVHihCg75yc9eofb+45nx/x3LidEiROixAlR4oQocUKUOCFKnBBl53xj7+9jbu3V//yf4XJClDghSpwQJU6IEidEiROixAlRds6F2fFYissJUeKEKHFClDghSpwQJU6IEidE2Tnf8P9PUuFyQpQ4IUqcECVOiBInRIkTosQJUXbOlT37jmmnXY/LCVHihChxQpQ4IUqcECVOiBInRIkTovwQQszWI7//PLjD5YQocUKUOCFKnBAlTogSJ0SJE6KmMcbNh8fD+fZD/sujd0A74/O5XE/T3OcuJ0SJE6LECVHihChxQpQ4IUqcEGXnhI3ZOeHJiBOixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHTGGPr7wDMcDkhSpwQJU6IEidEiROixAlRfwFn5YUWAImPjQAAAABJRU5ErkJggg==\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "spike_data, spike_targets = spikegen.spike_conversion(data_it, targets_it, config, gain=0.25)\n",
    "spike_data_visualizer = spike_data[:,0,0]\n",
    "data_sample = spikeplot.spike_animator(spike_data_visualizer, x=28, y=28, T=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### To-do: 1) append \".to(device)\" to dataloaders\n",
    "#### To-do: 2) include functionality for the following datasets, as we will need to benchmark:\n",
    "##### a) CIFAR-10 converted to spikes\n",
    "##### b) NMNIST\n",
    "##### c) N-CIFAR-10?\n",
    "##### d) DVS Gesture\n",
    "##### d) EEG from Enea's Frontiers paper\n",
    "##### e)\n",
    "\n",
    "### 2.0 LIF Neuron & Architecture"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "9QXsrr6Mp5e_",
    "1EWDw3bip8Ie",
    "vFM8UV9CreIX",
    "xXkTAJ9ws1Y6",
    "OgkWg605tE1y",
    "OBt0WDzyujnk",
    "xC96eesMqYo-",
    "mszPTrYOluym",
    "VTHK-wAWV57B"
   ],
   "name": "Copy of quantAwareTrain.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}