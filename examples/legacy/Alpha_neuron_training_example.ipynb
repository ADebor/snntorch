{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rklDqluPYZB"
      },
      "source": [
        "## Example of training using the Alpha Neuron"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ptd12vmR7H8D",
        "outputId": "79499811-cc47-4470-f190-f3a8581df051"
      },
      "outputs": [],
      "source": [
        "# !git clone -b alpha_neuron --single-branch https://github.com/jeshraghian/snntorch.git\n",
        "!pip install snntorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5VNVo64L93Zo",
        "outputId": "69255447-8261-4119-f851-066c05ea510c"
      },
      "outputs": [],
      "source": [
        "# %cd snntorch\n",
        "import snntorch as snn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CEUipC6UPebM"
      },
      "source": [
        "## Import Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AQeg7QZ69fSt"
      },
      "outputs": [],
      "source": [
        "import snntorch as snn\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "import numpy as np\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0OEdE6bEPf20"
      },
      "source": [
        "## Define Network and Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MHmCvayV7LJR"
      },
      "outputs": [],
      "source": [
        "# test alpha neuron: can it learn?\n",
        "\n",
        "num_inputs = 28*28\n",
        "num_hidden = 1000\n",
        "num_outputs = 10\n",
        "\n",
        "# Training Parameters\n",
        "batch_size=128\n",
        "data_path='/tmp/data/mnist'\n",
        "\n",
        "# Temporal Dynamics\n",
        "num_steps = 25\n",
        "alpha = 0.9\n",
        "beta = 0.8\n",
        "\n",
        "dtype = torch.float\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")\n",
        "\n",
        "# Define Network\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        \n",
        "        # initialize layers\n",
        "        self.fc1 = nn.Linear(num_inputs, num_hidden)\n",
        "        self.lif1 = snn.Alpha(alpha=alpha, beta=beta)\n",
        "        self.fc2 = nn.Linear(num_hidden, num_outputs)\n",
        "        self.lif2 = snn.Alpha(alpha=alpha, beta=beta)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        spk1, syn_exc1, syn_inh1, mem1 = self.lif1.init_alpha(batch_size, num_hidden)\n",
        "        spk2, syn_exc2, syn_inh2, mem2 = self.lif2.init_alpha(batch_size, num_outputs)\n",
        "\n",
        "        # Record the final layer\n",
        "        spk2_rec = []\n",
        "        mem2_rec = []\n",
        "\n",
        "        for step in range(num_steps):\n",
        "\n",
        "            cur1 = self.fc1(x)\n",
        "            spk1, syn_exc1, syn_inh1, mem1 = self.lif1(cur1, syn_exc1, syn_inh1, mem1)\n",
        "            cur2 = self.fc2(spk1)\n",
        "            spk2, syn_exc2, syn_inh2, mem2 = self.lif2(cur2, syn_exc2, syn_inh2, mem2)\n",
        "\n",
        "            spk2_rec.append(spk2)\n",
        "            mem2_rec.append(mem2)\n",
        "\n",
        "        return torch.stack(spk2_rec, dim=0), torch.stack(mem2_rec, dim=0)\n",
        "  \n",
        "net = Net().to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2N00-2eDPl2G"
      },
      "source": [
        "## dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NblLifHj9qO-",
        "outputId": "e890995e-a9fd-490d-f278-caf6bce9c21e"
      },
      "outputs": [],
      "source": [
        "# Define a transform\n",
        "transform = transforms.Compose([\n",
        "            transforms.Resize((28, 28)),\n",
        "            transforms.Grayscale(),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0,), (1,))])\n",
        "\n",
        "mnist_train = datasets.MNIST(data_path, train=True, download=True, transform=transform)\n",
        "mnist_test = datasets.MNIST(data_path, train=False, download=True, transform=transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kx8nATF69tEk"
      },
      "outputs": [],
      "source": [
        "# Create DataLoaders\n",
        "train_loader = DataLoader(mnist_train, batch_size=batch_size, shuffle=True, drop_last=True)\n",
        "test_loader = DataLoader(mnist_test, batch_size=batch_size, shuffle=True, drop_last=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gqDmeDJcP_HL"
      },
      "source": [
        "## Print Accuracy Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EJYEQpHk-MzX"
      },
      "outputs": [],
      "source": [
        "def print_batch_accuracy(data, targets, train=False):\n",
        "    with torch.no_grad():\n",
        "      output, _ = net(data.view(batch_size, -1))\n",
        "      _, idx = output.sum(dim=0).max(1)\n",
        "      acc = np.mean((targets == idx).detach().cpu().numpy())\n",
        "\n",
        "      if train:\n",
        "          print(f\"Train Set Accuracy: {acc}\")\n",
        "      else:\n",
        "          print(f\"Test Set Accuracy: {acc}\")\n",
        "\n",
        "def train_printer():\n",
        "    print(f\"Epoch {epoch}, Minibatch {minibatch_counter}\")\n",
        "    print(f\"Train Set Loss: {loss_hist[counter]}\")\n",
        "    print(f\"Test Set Loss: {test_loss_hist[counter]}\")\n",
        "    print_batch_accuracy(data_it, targets_it, train=True)\n",
        "    print_batch_accuracy(testdata_it, testtargets_it, train=False)\n",
        "    print(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m2Zz5xesQBBk"
      },
      "source": [
        "## Define Loss & Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Uwvn33m-OuY"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.Adam(net.parameters(), lr=2e-4, betas=(0.9, 0.999))\n",
        "log_softmax_fn = nn.LogSoftmax(dim=-1)\n",
        "loss_fn = nn.NLLLoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wY-94aYrQCXE"
      },
      "source": [
        "## Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hQvfXduS-QmB",
        "outputId": "7ec1f1dc-ce3f-4834-f601-9b5c34245225"
      },
      "outputs": [],
      "source": [
        "loss_hist = []\n",
        "test_loss_hist = []\n",
        "counter = 0\n",
        "\n",
        "# Outer training loop\n",
        "for epoch in range(10):\n",
        "    minibatch_counter = 0\n",
        "    train_batch = iter(train_loader)\n",
        "\n",
        "    # Minibatch training loop\n",
        "    for data_it, targets_it in train_batch:\n",
        "        data_it = data_it.to(device)\n",
        "        targets_it = targets_it.to(device)\n",
        "\n",
        "        spk_rec, mem_rec = net(data_it.view(batch_size, -1))\n",
        "        log_p_y = log_softmax_fn(mem_rec)\n",
        "        loss_val = torch.zeros((1), dtype=dtype, device=device)\n",
        "\n",
        "        # Sum loss over time steps: BPTT\n",
        "        for step in range(num_steps):\n",
        "          loss_val += loss_fn(log_p_y[step], targets_it)\n",
        "\n",
        "        # Gradient calculation\n",
        "        optimizer.zero_grad()\n",
        "        loss_val.backward()\n",
        "\n",
        "        # Weight Update\n",
        "        optimizer.step()\n",
        "\n",
        "        # Store loss history for future plotting\n",
        "        loss_hist.append(loss_val.item())\n",
        "\n",
        "        # Test set\n",
        "        test_data = itertools.cycle(test_loader)\n",
        "        testdata_it, testtargets_it = next(test_data)\n",
        "        testdata_it = testdata_it.to(device)\n",
        "        testtargets_it = testtargets_it.to(device)\n",
        "\n",
        "        # Test set forward pass\n",
        "        with torch.no_grad():\n",
        "          test_spk, test_mem = net(testdata_it.view(batch_size, -1))\n",
        "\n",
        "          # Test set loss\n",
        "          log_p_ytest = log_softmax_fn(test_mem)\n",
        "          log_p_ytest = log_p_ytest.sum(dim=0)\n",
        "          loss_val_test = loss_fn(log_p_ytest, testtargets_it)\n",
        "          test_loss_hist.append(loss_val_test.item())\n",
        "\n",
        "          # Print test/train loss/accuracy\n",
        "          if counter % 50 == 0:\n",
        "              train_printer()\n",
        "          minibatch_counter += 1\n",
        "          counter += 1\n",
        "\n",
        "loss_hist_true_grad = loss_hist\n",
        "test_loss_hist_true_grad = test_loss_hist"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Alpha_code_example.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
