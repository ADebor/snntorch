{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## batch_size tests"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import snntorch as snn\r\n",
    "import torch\r\n",
    "import torch.nn as nn\r\n",
    "from torch.utils.data import DataLoader\r\n",
    "from torchvision import datasets, transforms\r\n",
    "import numpy as np\r\n",
    "import itertools\r\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# Network Architecture\r\n",
    "num_inputs = 28*28\r\n",
    "num_hidden = 1000\r\n",
    "num_outputs = 10\r\n",
    "\r\n",
    "# Training Parameters\r\n",
    "batch_size=128\r\n",
    "data_path='/data/mnist'\r\n",
    "\r\n",
    "# Temporal Dynamics\r\n",
    "num_steps = 25\r\n",
    "alpha = 0.7\r\n",
    "beta = 0.8\r\n",
    "\r\n",
    "dtype = torch.float\r\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Define a transform\r\n",
    "transform = transforms.Compose([\r\n",
    "            transforms.Resize((28, 28)),\r\n",
    "            transforms.Grayscale(),\r\n",
    "            transforms.ToTensor(),\r\n",
    "            transforms.Normalize((0,), (1,))])\r\n",
    "\r\n",
    "mnist_train = datasets.MNIST(data_path, train=True, download=True, transform=transform)\r\n",
    "mnist_test = datasets.MNIST(data_path, train=False, download=True, transform=transform)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# Create DataLoaders\r\n",
    "train_loader = DataLoader(mnist_train, batch_size=batch_size, shuffle=True, drop_last=False)\r\n",
    "test_loader = DataLoader(mnist_test, batch_size=batch_size, shuffle=True, drop_last=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# Define Network\r\n",
    "class Net(nn.Module):\r\n",
    "    def __init__(self):\r\n",
    "        super().__init__()\r\n",
    "\r\n",
    "        # Initialize layers\r\n",
    "        self.fc1 = nn.Linear(num_inputs, num_hidden)\r\n",
    "        self.lif1 = snn.Synaptic(alpha=alpha, beta=beta)\r\n",
    "        self.fc2 = nn.Linear(num_hidden, num_outputs)\r\n",
    "        self.lif2 = snn.Synaptic(alpha=alpha, beta=beta)\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "\r\n",
    "        # Initialize hidden states and outputs at t=0\r\n",
    "        syn1, mem1 = self.lif1.init_synaptic(num_hidden)  #  test: remove spk\r\n",
    "        syn2, mem2 = self.lif2.init_synaptic(num_outputs)\r\n",
    "        \r\n",
    "        # Record the final layer\r\n",
    "        spk2_rec = []\r\n",
    "        mem2_rec = []\r\n",
    "\r\n",
    "        for step in range(num_steps):\r\n",
    "            cur1 = self.fc1(x)\r\n",
    "            spk1, syn1, mem1 = self.lif1(cur1, syn1, mem1)\r\n",
    "            cur2 = self.fc2(spk1)\r\n",
    "            spk2, syn2, mem2 = self.lif2(cur2, syn2, mem2)\r\n",
    "\r\n",
    "            spk2_rec.append(spk2)\r\n",
    "            mem2_rec.append(mem2)\r\n",
    "\r\n",
    "        return torch.stack(spk2_rec, dim=0), torch.stack(mem2_rec, dim=0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "net = Net().to(device)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "`Stein` has been deprecated and will be removed in a future version. Use `Synaptic` instead.\n",
      "`Stein` has been deprecated and will be removed in a future version. Use `Synaptic` instead.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "def print_batch_accuracy(data, targets, train=False):\r\n",
    "    output, _ = net(data.view(batch_size, -1))\r\n",
    "    _, idx = output.sum(dim=0).max(1)\r\n",
    "    acc = np.mean((targets == idx).detach().cpu().numpy())\r\n",
    "\r\n",
    "    if train:\r\n",
    "        print(f\"Train Set Accuracy: {acc}\")\r\n",
    "    else:\r\n",
    "        print(f\"Test Set Accuracy: {acc}\")\r\n",
    "\r\n",
    "def train_printer():\r\n",
    "    print(f\"Epoch {epoch}, Minibatch {minibatch_counter}\")\r\n",
    "    print(f\"Train Set Loss: {loss_hist[counter]}\")\r\n",
    "    print(f\"Test Set Loss: {test_loss_hist[counter]}\")\r\n",
    "    print_batch_accuracy(data_it, targets_it, train=True)\r\n",
    "    print_batch_accuracy(testdata_it, testtargets_it, train=False)\r\n",
    "    print(\"\\n\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "optimizer = torch.optim.Adam(net.parameters(), lr=2e-4, betas=(0.9, 0.999))\r\n",
    "log_softmax_fn = nn.LogSoftmax(dim=-1)\r\n",
    "loss_fn = nn.NLLLoss()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "loss_hist = []\r\n",
    "test_loss_hist = []\r\n",
    "counter = 0\r\n",
    "\r\n",
    "# Outer training loop\r\n",
    "for epoch in range(1):\r\n",
    "    minibatch_counter = 0\r\n",
    "    train_batch = iter(train_loader)\r\n",
    "\r\n",
    "    # Minibatch training loop\r\n",
    "    for data_it, targets_it in train_batch:\r\n",
    "        data_it = data_it.to(device)\r\n",
    "        targets_it = targets_it.to(device)\r\n",
    "\r\n",
    "        batch_size = data_it.size()[0]  #  test: remove spk\r\n",
    "        \r\n",
    "        spk_rec, mem_rec = net(data_it.view(batch_size, -1))\r\n",
    "        log_p_y = log_softmax_fn(mem_rec)\r\n",
    "        loss_val = torch.zeros((1), dtype=dtype, device=device)\r\n",
    "\r\n",
    "        # Sum loss over time steps: BPTT\r\n",
    "        for step in range(num_steps):\r\n",
    "          loss_val += loss_fn(log_p_y[step], targets_it)\r\n",
    "\r\n",
    "        # Gradient calculation\r\n",
    "        optimizer.zero_grad()\r\n",
    "        loss_val.backward()\r\n",
    "\r\n",
    "        # Weight Update\r\n",
    "        optimizer.step()\r\n",
    "\r\n",
    "        # Store loss history for future plotting\r\n",
    "        loss_hist.append(loss_val.item())\r\n",
    "\r\n",
    "        # Test set\r\n",
    "        test_data = itertools.cycle(test_loader)\r\n",
    "        testdata_it, testtargets_it = next(test_data)\r\n",
    "        testdata_it = testdata_it.to(device)\r\n",
    "        testtargets_it = testtargets_it.to(device)\r\n",
    "\r\n",
    "        batch_size = testdata_it.size()[0]  #  test: remove spk\r\n",
    "\r\n",
    "        # Test set forward pass\r\n",
    "        test_spk, test_mem = net(testdata_it.view(batch_size, -1))\r\n",
    "\r\n",
    "        # Test set loss\r\n",
    "        log_p_ytest = log_softmax_fn(test_mem)\r\n",
    "        log_p_ytest = log_p_ytest.sum(dim=0)\r\n",
    "        loss_val_test = loss_fn(log_p_ytest, testtargets_it)\r\n",
    "        test_loss_hist.append(loss_val_test.item())\r\n",
    "\r\n",
    "        # Print test/train loss/accuracy\r\n",
    "        if counter % 50 == 0:\r\n",
    "            train_printer()\r\n",
    "        minibatch_counter += 1\r\n",
    "        counter += 1\r\n",
    "\r\n",
    "loss_hist_true_grad = loss_hist\r\n",
    "test_loss_hist_true_grad = test_loss_hist"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 0, Minibatch 0\n",
      "Train Set Loss: 76.86495971679688\n",
      "Test Set Loss: 56.226741790771484\n",
      "Train Set Accuracy: 0.1875\n",
      "Test Set Accuracy: 0.1796875\n",
      "\n",
      "\n",
      "Epoch 0, Minibatch 50\n",
      "Train Set Loss: 17.487354278564453\n",
      "Test Set Loss: 14.834465980529785\n",
      "Train Set Accuracy: 0.890625\n",
      "Test Set Accuracy: 0.9140625\n",
      "\n",
      "\n",
      "Epoch 0, Minibatch 100\n",
      "Train Set Loss: 13.294114112854004\n",
      "Test Set Loss: 15.876989364624023\n",
      "Train Set Accuracy: 0.9375\n",
      "Test Set Accuracy: 0.890625\n",
      "\n",
      "\n",
      "Epoch 0, Minibatch 150\n",
      "Train Set Loss: 14.225533485412598\n",
      "Test Set Loss: 12.264030456542969\n",
      "Train Set Accuracy: 0.875\n",
      "Test Set Accuracy: 0.8984375\n",
      "\n",
      "\n",
      "Epoch 0, Minibatch 200\n",
      "Train Set Loss: 16.187170028686523\n",
      "Test Set Loss: 14.389913558959961\n",
      "Train Set Accuracy: 0.875\n",
      "Test Set Accuracy: 0.890625\n",
      "\n",
      "\n",
      "Epoch 0, Minibatch 250\n",
      "Train Set Loss: 12.327922821044922\n",
      "Test Set Loss: 12.903144836425781\n",
      "Train Set Accuracy: 0.9140625\n",
      "Test Set Accuracy: 0.921875\n",
      "\n",
      "\n",
      "Epoch 0, Minibatch 300\n",
      "Train Set Loss: 9.990253448486328\n",
      "Test Set Loss: 10.313959121704102\n",
      "Train Set Accuracy: 0.9609375\n",
      "Test Set Accuracy: 0.9453125\n",
      "\n",
      "\n",
      "Epoch 0, Minibatch 350\n",
      "Train Set Loss: 10.76211929321289\n",
      "Test Set Loss: 10.937702178955078\n",
      "Train Set Accuracy: 0.9375\n",
      "Test Set Accuracy: 0.921875\n",
      "\n",
      "\n",
      "Epoch 0, Minibatch 400\n",
      "Train Set Loss: 9.256976127624512\n",
      "Test Set Loss: 9.538768768310547\n",
      "Train Set Accuracy: 0.8984375\n",
      "Test Set Accuracy: 0.9375\n",
      "\n",
      "\n",
      "Epoch 0, Minibatch 450\n",
      "Train Set Loss: 13.176480293273926\n",
      "Test Set Loss: 11.202169418334961\n",
      "Train Set Accuracy: 0.9296875\n",
      "Test Set Accuracy: 0.9296875\n",
      "\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "spk_rec.size()  # the final batch is 96!"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([25, 96, 10])"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "test_spk.size()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([25, 128, 10])"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}