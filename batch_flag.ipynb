{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## batch_size tests"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import snntorch as snn\r\n",
    "import torch\r\n",
    "import torch.nn as nn\r\n",
    "from torch.utils.data import DataLoader\r\n",
    "from torchvision import datasets, transforms\r\n",
    "import numpy as np\r\n",
    "import itertools\r\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# Network Architecture\r\n",
    "num_inputs = 28*28\r\n",
    "num_hidden = 1000\r\n",
    "num_outputs = 10\r\n",
    "\r\n",
    "# Training Parameters\r\n",
    "batch_size=128\r\n",
    "data_path='/data/mnist'\r\n",
    "\r\n",
    "# Temporal Dynamics\r\n",
    "num_steps = 25\r\n",
    "alpha = 0.7\r\n",
    "beta = 0.8\r\n",
    "\r\n",
    "dtype = torch.float\r\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Define a transform\r\n",
    "transform = transforms.Compose([\r\n",
    "            transforms.Resize((28, 28)),\r\n",
    "            transforms.Grayscale(),\r\n",
    "            transforms.ToTensor(),\r\n",
    "            transforms.Normalize((0,), (1,))])\r\n",
    "\r\n",
    "mnist_train = datasets.MNIST(data_path, train=True, download=True, transform=transform)\r\n",
    "mnist_test = datasets.MNIST(data_path, train=False, download=True, transform=transform)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# Create DataLoaders\r\n",
    "train_loader = DataLoader(mnist_train, batch_size=batch_size, shuffle=True, drop_last=True)\r\n",
    "test_loader = DataLoader(mnist_test, batch_size=batch_size, shuffle=True, drop_last=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "# Define Network\r\n",
    "class Net(nn.Module):\r\n",
    "    def __init__(self):\r\n",
    "        super().__init__()\r\n",
    "\r\n",
    "        # Initialize layers\r\n",
    "        self.fc1 = nn.Linear(num_inputs, num_hidden)\r\n",
    "        self.lif1 = snn.Stein(alpha=alpha, beta=beta)\r\n",
    "        self.fc2 = nn.Linear(num_hidden, num_outputs)\r\n",
    "        self.lif2 = snn.Stein(alpha=alpha, beta=beta)\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "\r\n",
    "        # Initialize hidden states and outputs at t=0\r\n",
    "        spk1, syn1, mem1 = self.lif1.init_stein(num_hidden)\r\n",
    "        spk2, syn2, mem2 = self.lif2.init_stein(num_outputs)\r\n",
    "        print(spk2.__class__)\r\n",
    "        \r\n",
    "        # Record the final layer\r\n",
    "        spk2_rec = []\r\n",
    "        mem2_rec = []\r\n",
    "\r\n",
    "        for step in range(num_steps):\r\n",
    "            cur1 = self.fc1(x)\r\n",
    "            spk1, syn1, mem1 = self.lif1(cur1, syn1, mem1)\r\n",
    "            cur2 = self.fc2(spk1)\r\n",
    "            spk2, syn2, mem2 = self.lif2(cur2, syn2, mem2)\r\n",
    "\r\n",
    "            spk2_rec.append(spk2)\r\n",
    "            mem2_rec.append(mem2)\r\n",
    "\r\n",
    "        return torch.stack(spk2_rec, dim=0), torch.stack(mem2_rec, dim=0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "net = Net().to(device)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "`Stein` has been deprecated and will be removed in a future version. Use `Synaptic` instead.\n",
      "`Stein` has been deprecated and will be removed in a future version. Use `Synaptic` instead.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "def print_batch_accuracy(data, targets, train=False):\r\n",
    "    output, _ = net(data.view(batch_size, -1))\r\n",
    "    _, idx = output.sum(dim=0).max(1)\r\n",
    "    acc = np.mean((targets == idx).detach().cpu().numpy())\r\n",
    "\r\n",
    "    if train:\r\n",
    "        print(f\"Train Set Accuracy: {acc}\")\r\n",
    "    else:\r\n",
    "        print(f\"Test Set Accuracy: {acc}\")\r\n",
    "\r\n",
    "def train_printer():\r\n",
    "    print(f\"Epoch {epoch}, Minibatch {minibatch_counter}\")\r\n",
    "    print(f\"Train Set Loss: {loss_hist[counter]}\")\r\n",
    "    print(f\"Test Set Loss: {test_loss_hist[counter]}\")\r\n",
    "    print_batch_accuracy(data_it, targets_it, train=True)\r\n",
    "    print_batch_accuracy(testdata_it, testtargets_it, train=False)\r\n",
    "    print(\"\\n\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "optimizer = torch.optim.Adam(net.parameters(), lr=2e-4, betas=(0.9, 0.999))\r\n",
    "log_softmax_fn = nn.LogSoftmax(dim=-1)\r\n",
    "loss_fn = nn.NLLLoss()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "loss_hist = []\r\n",
    "test_loss_hist = []\r\n",
    "counter = 0\r\n",
    "\r\n",
    "# Outer training loop\r\n",
    "for epoch in range(1):\r\n",
    "    minibatch_counter = 0\r\n",
    "    train_batch = iter(train_loader)\r\n",
    "\r\n",
    "    # Minibatch training loop\r\n",
    "    for data_it, targets_it in train_batch:\r\n",
    "        data_it = data_it.to(device)\r\n",
    "        targets_it = targets_it.to(device)\r\n",
    "\r\n",
    "        spk_rec, mem_rec = net(data_it.view(batch_size, -1))\r\n",
    "        log_p_y = log_softmax_fn(mem_rec)\r\n",
    "        loss_val = torch.zeros((1), dtype=dtype, device=device)\r\n",
    "\r\n",
    "        # Sum loss over time steps: BPTT\r\n",
    "        for step in range(num_steps):\r\n",
    "          loss_val += loss_fn(log_p_y[step], targets_it)\r\n",
    "\r\n",
    "        # Gradient calculation\r\n",
    "        optimizer.zero_grad()\r\n",
    "        loss_val.backward()\r\n",
    "\r\n",
    "        # Weight Update\r\n",
    "        optimizer.step()\r\n",
    "\r\n",
    "        # Store loss history for future plotting\r\n",
    "        loss_hist.append(loss_val.item())\r\n",
    "\r\n",
    "        # Test set\r\n",
    "        test_data = itertools.cycle(test_loader)\r\n",
    "        testdata_it, testtargets_it = next(test_data)\r\n",
    "        testdata_it = testdata_it.to(device)\r\n",
    "        testtargets_it = testtargets_it.to(device)\r\n",
    "\r\n",
    "        # Test set forward pass\r\n",
    "        test_spk, test_mem = net(testdata_it.view(batch_size, -1))\r\n",
    "\r\n",
    "        # Test set loss\r\n",
    "        log_p_ytest = log_softmax_fn(test_mem)\r\n",
    "        log_p_ytest = log_p_ytest.sum(dim=0)\r\n",
    "        loss_val_test = loss_fn(log_p_ytest, testtargets_it)\r\n",
    "        test_loss_hist.append(loss_val_test.item())\r\n",
    "\r\n",
    "        # Print test/train loss/accuracy\r\n",
    "        if counter % 50 == 0:\r\n",
    "            train_printer()\r\n",
    "        minibatch_counter += 1\r\n",
    "        counter += 1\r\n",
    "\r\n",
    "loss_hist_true_grad = loss_hist\r\n",
    "test_loss_hist_true_grad = test_loss_hist"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "stack expects each tensor to be equal size, but got [10] at entry 0 and [128, 10] at entry 2",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-ee7e7207f92e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mtargets_it\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtargets_it\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0mspk_rec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmem_rec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_it\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m         \u001b[0mlog_p_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlog_softmax_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmem_rec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mloss_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jeshr\\Dropbox\\repos\\snntorch\\snnenv\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-25-8bc4e3aa0736>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     30\u001b[0m             \u001b[0mmem2_rec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmem2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspk2_rec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmem2_rec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [10] at entry 0 and [128, 10] at entry 2"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}